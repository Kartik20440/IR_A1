{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../CSE508_Winter2023_Dataset/InvertedIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the invertedindex data\n",
    "with open('invertedindex.pickle', 'rb') as handle:\n",
    "    invertedindex = pickle.load(handle)\n",
    "\n",
    "def get_posting_list(term):\n",
    "    if term in invertedindex:\n",
    "        return invertedindex[term][0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def get_posting_listsize(term):\n",
    "    if term in invertedindex:\n",
    "        return invertedindex[term][1]\n",
    "\n",
    "os.chdir('../CSE508_Winter2023_Dataset')\n",
    "all_docs = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and query and number of minimum iterations to find and of two terms\n",
    "def and_query(term1, term2):\n",
    "    posting_list1 = get_posting_list(term1)\n",
    "    posting_list2 = get_posting_list(term2)\n",
    "    posting_list1_size = get_posting_listsize(term1)\n",
    "    posting_list2_size = get_posting_listsize(term2)\n",
    "    return and_query_helper(posting_list1, posting_list1_size, posting_list2, posting_list2_size)\n",
    "\n",
    "def and_query_helper(posting_list1, size1, posting_list2, size2):\n",
    "    result = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < size1 and j < size2:\n",
    "        count += 1\n",
    "        if posting_list1[i] == posting_list2[j]:\n",
    "            result.append(posting_list1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif posting_list1[i] < posting_list2[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return result, count\n",
    "\n",
    "\n",
    "def and_not_query(term1, term2):\n",
    "    posting_list1 = get_posting_list(term1)\n",
    "    posting_list2 = get_posting_list(term2)\n",
    "    posting_list1_size = get_posting_listsize(term1)\n",
    "    posting_list2_size = get_posting_listsize(term2)\n",
    "    return and_not_query_helper(posting_list1, posting_list1_size, posting_list2, posting_list2_size)\n",
    "\n",
    "\n",
    "def and_not_query_helper(posting_list1, size1, posting_list2, size2):\n",
    "    result = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < size1 and j < size2:\n",
    "        count += 1\n",
    "        if posting_list1[i] == posting_list2[j]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif posting_list1[i] < posting_list2[j]:\n",
    "            result.append(posting_list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    while i < size1:\n",
    "        count+=1\n",
    "        result.append(posting_list1[i])\n",
    "        i += 1\n",
    "    return result, count\n",
    "\n",
    "def or_query(term1, term2):\n",
    "    posting_list1 = get_posting_list(term1)\n",
    "    posting_list2 = get_posting_list(term2)\n",
    "    posting_list1_size = get_posting_listsize(term1)\n",
    "    posting_list2_size = get_posting_listsize(term2)\n",
    "    return or_query_helper(posting_list1, posting_list1_size, posting_list2, posting_list2_size)\n",
    "\n",
    "\n",
    "\n",
    "def or_query_helper(posting_list1, size1, posting_list2, size2):\n",
    "    result = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < size1 and j < size2:\n",
    "        count += 1\n",
    "        if posting_list1[i] == posting_list2[j]:\n",
    "            result.append(posting_list1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif posting_list1[i] < posting_list2[j]:\n",
    "            result.append(posting_list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(posting_list2[j])\n",
    "            j += 1\n",
    "    if i < size1:\n",
    "        count += 1\n",
    "        result.extend(posting_list1[i::])\n",
    "    if j < size2:\n",
    "        count += 1\n",
    "        result.extend(posting_list2[j::])\n",
    "    return result, count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def or_not_query_helper(posting_list1, size1, posting_list2, size2):\n",
    "    result = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    while i < size1 and j < size2:\n",
    "        count += 1\n",
    "        if posting_list1[i] == posting_list2[j]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif posting_list1[i] < posting_list2[j]:\n",
    "            result.append(posting_list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    while i < size1:\n",
    "        count += 1\n",
    "        result.append(posting_list1[i])\n",
    "        i += 1\n",
    "    return result, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(or_query('slab', 'subjected'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['cranfield0005', 'cranfield0006', 'cranfield0029', 'cranfield0031', 'cranfield0051', 'cranfield0066', 'cranfield0090', 'cranfield0091', 'cranfield0144', 'cranfield0229', 'cranfield0274', 'cranfield0349', 'cranfield0386', 'cranfield0391', 'cranfield0395', 'cranfield0419', 'cranfield0454', 'cranfield0485', 'cranfield0509', 'cranfield0533', 'cranfield0579', 'cranfield0582', 'cranfield0587', 'cranfield0596', 'cranfield0625', 'cranfield0627', 'cranfield0640', 'cranfield0644', 'cranfield0707', 'cranfield0720', 'cranfield0721', 'cranfield0723', 'cranfield0726', 'cranfield0729', 'cranfield0735', 'cranfield0743', 'cranfield0779', 'cranfield0820', 'cranfield0822', 'cranfield0827', 'cranfield0836', 'cranfield0837', 'cranfield0838', 'cranfield0845', 'cranfield0846', 'cranfield0863', 'cranfield0868', 'cranfield0884', 'cranfield0887', 'cranfield0891', 'cranfield0938', 'cranfield0952', 'cranfield0957', 'cranfield0982', 'cranfield1022', 'cranfield1031', 'cranfield1037', 'cranfield1043', 'cranfield1055', 'cranfield1056', 'cranfield1058', 'cranfield1060', 'cranfield1068', 'cranfield1125', 'cranfield1132', 'cranfield1134', 'cranfield1145', 'cranfield1178', 'cranfield1279', 'cranfield1294', 'cranfield1361', 'cranfield1363', 'cranfield1399']\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now input and output\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cranfield0036', 'cranfield0212', 'cranfield0227', 'cranfield0548', 'cranfield0740', 'cranfield1039', 'cranfield1136', 'cranfield1147', 'cranfield1308']\n",
      "1226\n"
     ]
    }
   ],
   "source": [
    "#take an input n denoting number of queries\n",
    "# the next 2*n lines contain queries in the format, input sequence in first line followed by the operations to be performed in next line.\n",
    "\n",
    "def main():\n",
    "    n = int(input())\n",
    "    phrase = []\n",
    "    ops = []\n",
    "    for _ in range(n):\n",
    "        input_sequence = input()\n",
    "        operations = input()\n",
    "        phrase.append(input_sequence)\n",
    "        ops.append(operations)\n",
    "\n",
    "    for i in range(n):\n",
    "        query = phrase[i]\n",
    "        # query = query.split()\n",
    "        query = query.lower()\n",
    "        # Perform tokenization\n",
    "        tokens = word_tokenize(query)\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "        # Remove punctuations\n",
    "        tokens = [w for w in tokens if w.isalpha()]\n",
    "        # Remove blank space tokens\n",
    "        tokens = [w for w in tokens if w.strip()]\n",
    "        query = set(tokens)\n",
    "        op = ops[i]\n",
    "        op = op.split(',')\n",
    "\n",
    "        query = list(query)\n",
    "        result = get_posting_list(query[0])\n",
    "        size = get_posting_listsize(query[0])\n",
    "        itr = 0\n",
    "        TotalCount =0\n",
    "        # print(op)\n",
    "        # print(query)\n",
    "        while(itr<len(op)):\n",
    "            if op[itr] == 'AND':\n",
    "                result, count = and_query_helper(result, size, get_posting_list(query[itr+1]), get_posting_listsize(query[itr+1]))\n",
    "                \n",
    "                TotalCount += count\n",
    "                size = len(result)\n",
    "            elif op[itr] == 'OR':\n",
    "                # print(query[itr+1])\n",
    "                result, count = or_query_helper(result, size, get_posting_list(query[itr+1]), get_posting_listsize(query[itr+1]))\n",
    "                # result = set(result)\n",
    "                TotalCount += count\n",
    "                size = len(result)\n",
    "            elif op[itr] == 'AND NOT':\n",
    "                # print(query[itr+1])\n",
    "                result, count = and_not_query_helper(result, size, get_posting_list(query[itr+1]), get_posting_listsize(query[itr+1]))\n",
    "                # result = set(result)\n",
    "                TotalCount += count\n",
    "                size = len(result)\n",
    "            elif op[itr] == 'OR NOT':\n",
    "                result, count = or_not_query_helper(result, size, get_posting_list(query[itr+1]), get_posting_listsize(query[itr+1]))\n",
    "                # result = set(result)\n",
    "                TotalCount += count\n",
    "                size = len(result)\n",
    "            itr += 1\n",
    "        print(result)\n",
    "        print(TotalCount)\n",
    "        \n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
